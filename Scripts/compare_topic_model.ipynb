{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing topic modelling techniques\n",
    "\n",
    "There are different topic modelling approaches, each with a different set of advantages and disadvantages. The 'best' modelling technique is far from absolute, and largely depends on the nuances of the text data being analysed. To our knowledge, PFD data has not yet been analysed via NLP or topic modelling techniques, meaning that there exists no literature on the optimal approach(es).\n",
    "\n",
    "This notebook will compare the suitability of 5 topic modelling techniques for PFD 'concerns' data.<br><br><br>\n",
    "\n",
    "\n",
    "1. **Latent Dirichlet Allocation (LDA)**\n",
    "\n",
    "LDA is perhaps the most popular topic modelling technique. It is a probabilistic method that assumes each document is a mixture of various topics (likely suitable for PFD reports which frequently contain multiple concerns). It characterises topics as a 'mixture of words'; the model generates a topic distribution for each document and a word distribution for each topic.\n",
    "\n",
    "LDA *does* require that we pre-define our number of topics.\n",
    "\n",
    "It uses Dirichlet distribution priors to model the distribution of topics in documents and words in topics, providing a more statistically aligned framework for topic modelling.<br><br><br>\n",
    "\n",
    "\n",
    "2. **Correlated Topic Modelling (CTM)**\n",
    "\n",
    "CTM is an extension of LDA that allows for correlations between topics. While it carries over core disadvantages of LDA in terms of less interpretable keyword lists for each topic, its unique contribution is its inclusion of a covariance structure to model topic correlations. This is particularly interesting for our PFD data, where many reports are built from multiple concerns and therefore topics. \n",
    "\n",
    "CTM *does* require us to pre-define our number of topics.<br><br><br>\n",
    "\n",
    "\n",
    "3. **Non-negative Matrix Factorisation (NMF)**\n",
    "\n",
    "NMF is a matrix factorisation technique that decomposes the document-term matrix into two lower-dimensional matrices. Topics are characterised by non-negative components in the factorised matrices, representing the importance of words in topics and topics in documents. Similarly to LDA, it assumes that documents contain multiple topics.\n",
    "\n",
    "NMF *does* require that we pre-define our number of topics.\n",
    "\n",
    "NMF enforces non-negativity constraints. Many report that resulting topic keywords are therefore more interpretable than LDA, with less 'noise' in the keyword lists.<br><br><br>\n",
    "\n",
    "\n",
    "4. **Top2Vec**\n",
    "\n",
    "Topics in Top2Vec are characterised by dense clusters of document and word embeddings. These clusters are identified in a joint embedding space, where both documents and words are represented. It does allow for multiple topics per document; this is achieved through the proximity of document embeddings to multiple topic vectors in the semantic space.\n",
    "\n",
    "Top2Vec does *not* require us to pre-define our number of topics.\n",
    "\n",
    "Top2Vec uses deep learning-based embeddings (e.g., Doc2Vec, Universal Sentence Encoder) to capture the semantic relationships in the text. This method ensures that topics are discovered based on the natural clustering of similar documents and words, leading to a more intuitive and data-driven identification of topics.<br><br><br>\n",
    "\n",
    "\n",
    "5. **BERTopic**\n",
    "\n",
    "BERTopic uses BERT embeddings and clustering algorithms to discover topics. Topics are characterised by dense clusters of semantically similar embeddings, identified through dimensionality reduction and clustering. Although not originally supported, v0.13 (January 2023) allows us to approximate a probabilistic topic distribution for each report via '.approximate_distribution'.\n",
    "\n",
    "BERTopic does *not* require us to pre-define our number of topics.<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanContent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0318</th>\n",
       "      <td>Pre-amble Mr Larsen was a 52 year old male wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0311</th>\n",
       "      <td>(1) The process for triaging and prioritising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0298</th>\n",
       "      <td>(1) There are questions and answers on Quora’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0297</th>\n",
       "      <td>(1) The prison service instruction (PSI) 64/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0296</th>\n",
       "      <td>My principal concern is that when a high-risk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2016-0037</th>\n",
       "      <td>Barts and the London 1. Whilst it was clear to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0465</th>\n",
       "      <td>1. Piotr Kucharz was a Polish gentleman who co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0173</th>\n",
       "      <td>Camden and Islington Trust 1. It seemed from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0116</th>\n",
       "      <td>1. The deceased was a design engineer and his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0072</th>\n",
       "      <td>I'm sorry, but I need the specific leading int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     CleanContent\n",
       "ID                                                               \n",
       "Ref: 2024-0318   Pre-amble Mr Larsen was a 52 year old male wi...\n",
       "Ref: 2024-0311  (1) The process for triaging and prioritising ...\n",
       "Ref: 2024-0298  (1) There are questions and answers on Quora’s...\n",
       "Ref: 2024-0297  (1) The prison service instruction (PSI) 64/20...\n",
       "Ref: 2024-0296  My principal concern is that when a high-risk ...\n",
       "...                                                           ...\n",
       "Ref: 2016-0037  Barts and the London 1. Whilst it was clear to...\n",
       "Ref: 2015-0465  1. Piotr Kucharz was a Polish gentleman who co...\n",
       "Ref: 2015-0173  Camden and Islington Trust 1. It seemed from t...\n",
       "Ref: 2015-0116  1. The deceased was a design engineer and his ...\n",
       "Ref: 2015-0072  I'm sorry, but I need the specific leading int...\n",
       "\n",
       "[415 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import cleaned data\n",
    "data = pd.read_csv('../Data/cleaned.csv', index_col='ID')\n",
    "\n",
    "# Just keep \"CleanContent\" field\n",
    "data = data[['CleanContent']]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and process data\n",
    "\n",
    "Before topic modelling, we need to: (1) tokenize the data; (2) remove punctuation, special characters and numbers; (3) remove stop words; (4) lemmatize tokens to their dictionary base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/sam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sam/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/sam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanContent</th>\n",
       "      <th>TokenisedContent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0318</th>\n",
       "      <td>Pre-amble Mr Larsen was a 52 year old male wi...</td>\n",
       "      <td>[Mr, Larsen, year, old, male, history, mental,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0311</th>\n",
       "      <td>(1) The process for triaging and prioritising ...</td>\n",
       "      <td>[The, process, triaging, prioritising, ambulan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0298</th>\n",
       "      <td>(1) There are questions and answers on Quora’s...</td>\n",
       "      <td>[There, questions, answers, Quora, website, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0297</th>\n",
       "      <td>(1) The prison service instruction (PSI) 64/20...</td>\n",
       "      <td>[The, prison, service, instruction, PSI, sets,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0296</th>\n",
       "      <td>My principal concern is that when a high-risk ...</td>\n",
       "      <td>[My, principal, concern, mental, health, patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2016-0037</th>\n",
       "      <td>Barts and the London 1. Whilst it was clear to...</td>\n",
       "      <td>[Barts, London, Whilst, clear, evidence, I, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0465</th>\n",
       "      <td>1. Piotr Kucharz was a Polish gentleman who co...</td>\n",
       "      <td>[Piotr, Kucharz, Polish, gentleman, commenced,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0173</th>\n",
       "      <td>Camden and Islington Trust 1. It seemed from t...</td>\n",
       "      <td>[Camden, Islington, Trust, It, seemed, evidenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0116</th>\n",
       "      <td>1. The deceased was a design engineer and his ...</td>\n",
       "      <td>[The, deceased, design, engineer, sketches, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0072</th>\n",
       "      <td>I'm sorry, but I need the specific leading int...</td>\n",
       "      <td>[I, sorry, I, need, specific, leading, introdu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     CleanContent  \\\n",
       "ID                                                                  \n",
       "Ref: 2024-0318   Pre-amble Mr Larsen was a 52 year old male wi...   \n",
       "Ref: 2024-0311  (1) The process for triaging and prioritising ...   \n",
       "Ref: 2024-0298  (1) There are questions and answers on Quora’s...   \n",
       "Ref: 2024-0297  (1) The prison service instruction (PSI) 64/20...   \n",
       "Ref: 2024-0296  My principal concern is that when a high-risk ...   \n",
       "...                                                           ...   \n",
       "Ref: 2016-0037  Barts and the London 1. Whilst it was clear to...   \n",
       "Ref: 2015-0465  1. Piotr Kucharz was a Polish gentleman who co...   \n",
       "Ref: 2015-0173  Camden and Islington Trust 1. It seemed from t...   \n",
       "Ref: 2015-0116  1. The deceased was a design engineer and his ...   \n",
       "Ref: 2015-0072  I'm sorry, but I need the specific leading int...   \n",
       "\n",
       "                                                 TokenisedContent  \n",
       "ID                                                                 \n",
       "Ref: 2024-0318  [Mr, Larsen, year, old, male, history, mental,...  \n",
       "Ref: 2024-0311  [The, process, triaging, prioritising, ambulan...  \n",
       "Ref: 2024-0298  [There, questions, answers, Quora, website, pr...  \n",
       "Ref: 2024-0297  [The, prison, service, instruction, PSI, sets,...  \n",
       "Ref: 2024-0296  [My, principal, concern, mental, health, patie...  \n",
       "...                                                           ...  \n",
       "Ref: 2016-0037  [Barts, London, Whilst, clear, evidence, I, he...  \n",
       "Ref: 2015-0465  [Piotr, Kucharz, Polish, gentleman, commenced,...  \n",
       "Ref: 2015-0173  [Camden, Islington, Trust, It, seemed, evidenc...  \n",
       "Ref: 2015-0116  [The, deceased, design, engineer, sketches, fo...  \n",
       "Ref: 2015-0072  [I, sorry, I, need, specific, leading, introdu...  \n",
       "\n",
       "[415 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Tokenize the report content\n",
    "data['TokenisedContent'] = data['CleanContent'].apply(word_tokenize)\n",
    "\n",
    "# Remove punctuation, special characters and numbers\n",
    "data['TokenisedContent'] = data['TokenisedContent'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['TokenisedContent'] = data['TokenisedContent'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map POS tags for lemmatization\n",
    "# ...J = Adjective, R = Adverb, V = Verb, N = Noun\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanContent</th>\n",
       "      <th>TokenisedContent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0318</th>\n",
       "      <td>Pre-amble Mr Larsen was a 52 year old male wi...</td>\n",
       "      <td>[Mr, Larsen, year, old, male, history, mental,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0311</th>\n",
       "      <td>(1) The process for triaging and prioritising ...</td>\n",
       "      <td>[The, process, triaging, prioritise, ambulance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0298</th>\n",
       "      <td>(1) There are questions and answers on Quora’s...</td>\n",
       "      <td>[There, question, answer, Quora, website, prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0297</th>\n",
       "      <td>(1) The prison service instruction (PSI) 64/20...</td>\n",
       "      <td>[The, prison, service, instruction, PSI, set, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2024-0296</th>\n",
       "      <td>My principal concern is that when a high-risk ...</td>\n",
       "      <td>[My, principal, concern, mental, health, patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2016-0037</th>\n",
       "      <td>Barts and the London 1. Whilst it was clear to...</td>\n",
       "      <td>[Barts, London, Whilst, clear, evidence, I, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0465</th>\n",
       "      <td>1. Piotr Kucharz was a Polish gentleman who co...</td>\n",
       "      <td>[Piotr, Kucharz, Polish, gentleman, commence, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0173</th>\n",
       "      <td>Camden and Islington Trust 1. It seemed from t...</td>\n",
       "      <td>[Camden, Islington, Trust, It, seem, evidence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0116</th>\n",
       "      <td>1. The deceased was a design engineer and his ...</td>\n",
       "      <td>[The, deceased, design, engineer, sketch, find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref: 2015-0072</th>\n",
       "      <td>I'm sorry, but I need the specific leading int...</td>\n",
       "      <td>[I, sorry, I, need, specific, lead, introducto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     CleanContent  \\\n",
       "ID                                                                  \n",
       "Ref: 2024-0318   Pre-amble Mr Larsen was a 52 year old male wi...   \n",
       "Ref: 2024-0311  (1) The process for triaging and prioritising ...   \n",
       "Ref: 2024-0298  (1) There are questions and answers on Quora’s...   \n",
       "Ref: 2024-0297  (1) The prison service instruction (PSI) 64/20...   \n",
       "Ref: 2024-0296  My principal concern is that when a high-risk ...   \n",
       "...                                                           ...   \n",
       "Ref: 2016-0037  Barts and the London 1. Whilst it was clear to...   \n",
       "Ref: 2015-0465  1. Piotr Kucharz was a Polish gentleman who co...   \n",
       "Ref: 2015-0173  Camden and Islington Trust 1. It seemed from t...   \n",
       "Ref: 2015-0116  1. The deceased was a design engineer and his ...   \n",
       "Ref: 2015-0072  I'm sorry, but I need the specific leading int...   \n",
       "\n",
       "                                                 TokenisedContent  \n",
       "ID                                                                 \n",
       "Ref: 2024-0318  [Mr, Larsen, year, old, male, history, mental,...  \n",
       "Ref: 2024-0311  [The, process, triaging, prioritise, ambulance...  \n",
       "Ref: 2024-0298  [There, question, answer, Quora, website, prov...  \n",
       "Ref: 2024-0297  [The, prison, service, instruction, PSI, set, ...  \n",
       "Ref: 2024-0296  [My, principal, concern, mental, health, patie...  \n",
       "...                                                           ...  \n",
       "Ref: 2016-0037  [Barts, London, Whilst, clear, evidence, I, he...  \n",
       "Ref: 2015-0465  [Piotr, Kucharz, Polish, gentleman, commence, ...  \n",
       "Ref: 2015-0173  [Camden, Islington, Trust, It, seem, evidence,...  \n",
       "Ref: 2015-0116  [The, deceased, design, engineer, sketch, find...  \n",
       "Ref: 2015-0072  [I, sorry, I, need, specific, lead, introducto...  \n",
       "\n",
       "[415 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function to process tokens\n",
    "def process_content(content):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(content)\n",
    "    \n",
    "    # Remove punctuation, special characters and numbers\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # POS tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Lemmatize with POS tags\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(tag)) if get_wordnet_pos(tag) else token for token, tag in pos_tags]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "\n",
    "data['TokenisedContent'] = data['CleanContent'].apply(process_content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PFD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
