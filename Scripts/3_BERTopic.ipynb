{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing BERTopic for PFD reports\n",
    "\n",
    "BERTopic uses BERT embeddings and clustering algorithms to discover topics. Topics are characterised by dense clusters of semantically similar embeddings, identified through dimensionality reduction and clustering. \n",
    "\n",
    "Rather than a model, BERTopic is a framework that contains a handful of sub-models, each providing a necessary step in topic representation. These are:\n",
    "* **Embeddings.** This stage represents our text data as a numeric vector to capture sematic meaning and context. This is a core advantage of BERTopic compared to traditional methods such as LDA.\n",
    "* **Dimensionality reduction.** We then take the above embeddings vector and compresses its size to aid computational performance.\n",
    "* **Clustering.** We then cluster our reduced dimension embeddings via unsupervised methods. This essentially extracts our topics.\n",
    "* **TF-IDF.** 'Term Frequency - Inverse Document Frequency' is the approach taken to extract key words and phrases to represent our topic representations. The TF-IDF approach favours frequent terms but also terms that are unique across our wider text corpus.\n",
    "\n",
    "In BERTopic's modular design, each 'module' is independent, meaning that the specific algorithmic approach can be changed for any component, and the remaining steps will be compatible. \n",
    "\n",
    "<br>\n",
    "\n",
    "First, we need to read in our cleaned data...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read report data\n",
    "data = pd.read_csv('../Data/cleaned.csv')\n",
    "\n",
    "# Extract CleanContent column\n",
    "reports = data['CleanContent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "### Sentence splitter\n",
    "Before embedding our text, it's useful to first split our reports into sentences. BERTopic generally performs poorly on larger documents, as this tends to result in noisy topics. \n",
    "\n",
    "Splitting our reports into sentences means that BERTopic will not represent individual reports with a topic out-of-the-box, but we can do this manually (for example, by aggreagating topics within each report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = [sent_tokenize(report) for report in reports]\n",
    "sentences = [sentence for doc in sentences for sentence in doc]\n",
    "sentences = pd.DataFrame(sentences, columns=['sentences'])\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing with GPT\n",
    "\n",
    "Now with the reports in sentence format, we can use the OpenAI API to...\n",
    "* Correct spelling errors and grammatical mistakes - these create noise in our topic representations\n",
    "* Remove reference to dates, names and addresses - this preserves privacy and increases the relevancy of our data\n",
    "* In some circumstances, trim down sentences to reduce filler words\n",
    "\n",
    "First, we'll do this with a sample of 30 sentences to make sure everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Activate OpenAI API Key\n",
    "load_dotenv('api.env')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"\"\"You will be provided with a sentence. You must return the sentence - and nothing else whatsoever - with the following modifications:\n",
    "* Correct spelling and grammatical errors.\n",
    "* Remove *all* references to dates, including years.\n",
    "* Remove *all* references to addresses.\n",
    "* Remove *all* references to names or titles of individuals. For example, \"Sam went to the shop\" or \"Mr Andrews went to the shop\" would both be changed to \"They went to the shop\".\n",
    "* Keep the first-person \"I\" pronoun if it is used\n",
    "* Do *not* change acronyms or organisational names.\n",
    "* If I haven't provided you with a full sentence simply return what I've given you and nothing else. This might be a single number.\n",
    "\n",
    "Here is your sentence:\n",
    "{sentence}\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "# Construct prompts for each given report sentence\n",
    "def build_prompt(sentence: str) -> List[Dict[str, str]]:\n",
    "    # OpenAI 'messages' take a list of dictionaries, each with a 'role' and 'content' key. \n",
    "    # Role can be 'system', 'user', or 'assistant' (LLM replies as assistant); content is the text the LLM sees.\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt.format(sentence = sentence)},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Define empty array for new texts\n",
    "new_sentences = []\n",
    "original_sentences = []\n",
    "\n",
    "# Sample 30 sentences from the dataframe\n",
    "random.seed(12345)\n",
    "sample_sentences = random.sample(range(len(sentences)), 30)\n",
    "\n",
    "# Start the clock\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each sentence with GPT-3.5 Turbo\n",
    "for count, idx in enumerate(sample_sentences, start=1):\n",
    "    sentence = sentences['sentences'].iloc[idx]\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4-turbo\",\n",
    "                messages=build_prompt(sentence),\n",
    "                temperature=0,\n",
    "                seed=18062024\n",
    "            ).choices[0].message.content\n",
    "            \n",
    "            new_sentences.append(response)\n",
    "            \n",
    "            # Print progress and results\n",
    "            print(f\"Processing sentence {idx}\")\n",
    "            print(f\"Original: {sentence}\")\n",
    "            print(f\"New: {response}\\n\")\n",
    "            print(\"\")\n",
    "            \n",
    "            success = True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sentence {idx}: {e}\")\n",
    "            break\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate & print time taken\n",
    "total_time = end_time - start_time\n",
    "minutes = int(total_time // 60)\n",
    "seconds = total_time % 60\n",
    "\n",
    "print(f'Time taken: {minutes} minutes and {seconds:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have worked nicely. Names, dates and addresses have been consistently removed. No sentence has had its contents erronously changed.\n",
    "\n",
    "It's clear that some sentences aren't right in the original data. We have a number of references to numbers (e.g. \"4.\"). This is because our earlier sentence splitter designated sentences by the presence of full stops. Unfortunately, despite prompt engineering, it doesn't seem to be possible to force GPT to provide a blank string as its response, so we've had to return these erronous sentences as-is. \n",
    "\n",
    "There's nothing more we can do for the time being, so let's extend the above prompt on to our full data and hope that these erronous sentences don't significantly affect downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty array for new texts\n",
    "new_sentences = []\n",
    "\n",
    "# Start the clock\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each sentence with GPT-3.5 Turbo\n",
    "for idx in range(len(sentences)):\n",
    "    sentence = sentences['sentences'].iloc[idx]\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4-turbo\",\n",
    "                messages=build_prompt(sentence),\n",
    "                temperature=0,\n",
    "                seed=18062024\n",
    "            ).choices[0].message.content\n",
    "            \n",
    "            new_sentences.append(response)\n",
    "            success = True\n",
    "\n",
    "        except Exception as e:\n",
    "            break\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate & print time taken\n",
    "total_time = end_time - start_time\n",
    "minutes = int(total_time // 60)\n",
    "seconds = total_time % 60\n",
    "\n",
    "print(f'Time taken: {minutes} minutes and {seconds:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the above code takes ages to run, we'll first save the above into a .csv and load it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences = new_sentences\n",
    "processed_sentences = pd.DataFrame(processed_sentences, columns=['sentences'])\n",
    "processed_sentences.to_csv('../Data/processed_sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embeddings\n",
    "\n",
    "We first need to embed our data, representing our text in a numeric vector that captures semantic meaning. This is a huge advantage compared to methods like LDA, as we can take advantage of cutting-edge development of LM embeddings from the transformers architecture.\n",
    "\n",
    "BERT's out-of-the-box embeddings model doesn't really compete with more modern approaches. Luckily, we can customise this through calling any transformers model on Hugging Face or OpenAI. \n",
    "\n",
    "For ease of use, we'll use OpenAI's more advanced embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from bertopic.backend import OpenAIBackend\n",
    "\n",
    "# Activate OpenAI API Key\n",
    "load_dotenv('api.env')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "# Import processed sentences csv\n",
    "processed_sentences = pd.read_csv('../Data/processed_sentences.csv')\n",
    "\n",
    "# Change processed_sentences\n",
    "processed_sentences = processed_sentences['sentences'].tolist()\n",
    "\n",
    "# Change processed_sentences to array\n",
    "#processed_sentences_array = np.array(processed_sentences['sentences'])\n",
    "\n",
    "# Get embeddings\n",
    "embedding_model = OpenAIBackend(client, \"text-embedding-3-small\")\n",
    "\n",
    "# Generate embeddings\n",
    "#sentence_embeddings = embedding_model.embed(processed_sentences, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dimensionality reduction\n",
    "\n",
    "Our embeddings have high dimensionality, which poses a problem for downstream clustering tasks.\n",
    "\n",
    "**UMAP** is a dimensionality reduction technique that balances the preservation of local and global structures by constructing a high-dimensional graph of the data and optimising its low-dimensional representation. UMAP focuses on maintaining the local structure by ensuring that points that are close together in high-dimensional space remain close in the low-dimensional space. This is achieved through a neighborhood graph that captures local relationships. The relationships captured are, as far as possible, preserved in the lower-dimensional representation. \n",
    "\n",
    "Another option would be **PCA**. PCA is strictly linear and would effectively capture major themes in the PFD reports, such as the distinction between different types of issues (e.g., hospital vs. workplace safety) based on overall variance. However, smaller clusters of reports with very specific concerns might not be well-preserved, as PCA could mix them if their variance is not as significant compared to the global patterns.\n",
    "\n",
    "Any other dimensionality reduction model can also be imported from scikit-learn, so long as it has both a `.fit()` and `.transform()` method.\n",
    "\n",
    "Here's a quick comparison between UMAP and PCA...\n",
    "\n",
    "| Aspect               | PCA                                                          | UMAP                                                                 |\n",
    "|----------------------|--------------------------------------------------------------|----------------------------------------------------------------------|\n",
    "| Type                 | Linear                                                       | Non-linear                                                           |\n",
    "| Local Structure      | Not specifically preserved                                   | Well preserved                                                       |\n",
    "| Global Structure     | Well preserved                                               | Well preserved                                                       |\n",
    "| Computation          | Generally faster and less complex                            | More complex and computationally intensive                           |\n",
    "| Application Suitability | Best for data with linear relationships and when global patterns are of primary interest | Best for data with non-linear relationships and when both local and global patterns are important |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Since UMAP excels at maintaining local structures, it will effectively capture the relationships between our PFD report sentences that are similar. This is crucial when working at the sentence level, as we need to identify and group similar sentences together accurately.\n",
    "\n",
    "### Parameters for UMAP\n",
    "* `n_neighbors` - controls the local neighborhood size used for manifold approximation. It balances the focus between local versus global structure. Smaller values (e.g., 5-15) will capture very local structures and can lead to more detailed clustering. Larger values (e.g., 50-100) will incorporate more global structure and may provide a broader overview of the data.\n",
    "\n",
    "* `min_dist` - controls the minimum distance between points in the low-dimensional space. It affects the tightness of clusters. Smaller values (e.g., 0.001-0.1) will result in more compact clusters. Larger values (e.g., 0.1-0.5) will spread out clusters, potentially making broader patterns more apparent.\n",
    "\n",
    "* `n_components` - determines the number of dimensions for the reduced space. Usually set to 2 for visualisation purposes, but for more complex downstream tasks, 3 or more can be useful.\n",
    "\n",
    "<br>\n",
    "\n",
    "We'll experiment with different hyperparameters for UMAP, assessing the visualisation of the global projection of sentence embeddings. We can also look at the silhouette score, but this metric is not super informative for clusters of irregular shapes and different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a UMAP model\n",
    "umap_model = UMAP(n_neighbors=15, \n",
    "                  n_components=5,\n",
    "                  min_dist=0,\n",
    "                  random_state=230624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clustering\n",
    "\n",
    "Once we've reduced the dimensionality of our input embeddings, the next step is to cluster them into groups of similar embeddings to identify our topics. Clustering is arguably the most important step, as the effectiveness of our clustering method directly impacts the coherence of our topic representations.\n",
    "\n",
    "HDBSCAN is a very effective approach to clustering, as it can happily depict irregular shapes (e.g. not forcing clusters to be convex). Importantly, HDBSCAN does not force data into a cluster. If it cannot find a natural cluster for a data point, then it assigns it to a special 'outlier' topic (represented as \"-1\" in BERTopic). This makes our identified topics much tighter and more coherent. \n",
    "\n",
    "HDBSCAN has the following main hyperparameters...\n",
    "\n",
    "* `min_cluster_size` - the minimum size of clusters. Smaller values can lead to more fine-grained clusters, while larger values lead to more general clusters.\n",
    "\n",
    "* `metric` - the distance metric used. Common choices are 'euclidean', 'manhattan', 'cosine', etc. This choice should be based of data characteristics.\n",
    "\n",
    "* `cluster_selection_method` - the method to select clusters. 'eom' (excess of mass) is a common choice, but 'leaf' can also be used for a different clustering approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=20, # set to the number of clusters\n",
    "    #metric='cosine', # can choose euclidean, manhattan, cosine, etc.\n",
    "    cluster_selection_method='leaf', # can choose eom or leaf\n",
    "    prediction_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vectoriser\n",
    "\n",
    "After identifying clusters (topics), the vectorizer (often TF-IDF) is used to convert the original text data into a document-term matrix. This matrix represents the frequency of terms in each document while giving more weight to important terms (i.e., terms that are unique to a document relative to the entire corpus.\n",
    "\n",
    "It has the following hyperparameters:\n",
    "\n",
    "* `ngram_range` - allows us to specify the range of words that is allowed within a topic representation entity. For example, and ngran_range of (1,3) allows us to have 1, 2 and 3-word entities. This is important for phrases like \"mental health\" which could only be represented as \"mental\" and \"health\", seperately, if we had an ngram range of just 1.\n",
    "* `stop_words` - allows us to specify that we want stop words to be removed. We've already embedded our text, so removing stop words now will not harm the embedding process and helps to identify meaningful topics.\n",
    "* `min_df` - this parameter control the minimum number of times a word must be present for it to be assigned a topic. The c-TF-IDF will almost certainly remove these words anyway, so we can afford to be quite liberal with this parameter.\n",
    "* `max_df` - this controls the count of entities within each topic representation. Stipulating this could force some topics to be more precise, but with the disadvantage of exclusion. In many cases, it might be best to leave it blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(\n",
    "    min_df=20,\n",
    "    ngram_range=(1,3),\n",
    "    stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique topics identified: 58\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2022</td>\n",
       "      <td>-1_did_team_death_staff</td>\n",
       "      <td>[did, team, death, staff, evidence, inquest, c...</td>\n",
       "      <td>[The evidence heard at the Inquest was that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0_mental health_mental_health_team</td>\n",
       "      <td>[mental health, mental, health, team, patients...</td>\n",
       "      <td>[At HMP Haverigg there was inadequate mental h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>1_staff_guidance_issues_national</td>\n",
       "      <td>[staff, guidance, issues, national, informatio...</td>\n",
       "      <td>[There is a lack of national guidance for both...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>2_risk_information_assessment_plan</td>\n",
       "      <td>[risk, information, assessment, plan, care, pa...</td>\n",
       "      <td>[This gap in information can have an impact on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>3_patients_review_heard_evidence</td>\n",
       "      <td>[patients, review, heard, evidence, heard evid...</td>\n",
       "      <td>[I also heard evidence to suggest that prescri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>4_concerns_plan_information_care</td>\n",
       "      <td>[concerns, plan, information, care, place, did...</td>\n",
       "      <td>[They did not receive a care plan that was ade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>5_family___</td>\n",
       "      <td>[family, , , , , , , , , ]</td>\n",
       "      <td>[2., They's family 3., They's family 3.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>6____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[1., 1., 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>7_review_provided_care_staff</td>\n",
       "      <td>[review, provided, care, staff, report, policy...</td>\n",
       "      <td>[My concerns relating to the inadequacy of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>8_including_risk_assessment_does</td>\n",
       "      <td>[including, risk, assessment, does, guidance, ...</td>\n",
       "      <td>[There is the potential for the risk of harm t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>9_following_did_staff_response</td>\n",
       "      <td>[following, did, staff, response, service, tim...</td>\n",
       "      <td>[In the case of the individual, as can be seen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>73</td>\n",
       "      <td>10____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[3., 3., 3.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>11_staff_provided_heard evidence_available</td>\n",
       "      <td>[staff, provided, heard evidence, available, c...</td>\n",
       "      <td>[I heard evidence that training on dealing wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>12_mental_mental health_health_assessment</td>\n",
       "      <td>[mental, mental health, health, assessment, di...</td>\n",
       "      <td>[She felt she was not being listened to by com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>13_information___</td>\n",
       "      <td>[information, , , , , , , , , ]</td>\n",
       "      <td>[4., 4., For information 4.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>14_inquest_evidence_concern_heard</td>\n",
       "      <td>[inquest, evidence, concern, heard, heard evid...</td>\n",
       "      <td>[During the Inquest evidence was heard that: ­...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>15_given_policy_issues_relation</td>\n",
       "      <td>[given, policy, issues, relation, concerns, co...</td>\n",
       "      <td>[Consideration should be given to whether any ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>16_including_mental health_mental_does</td>\n",
       "      <td>[including, mental health, mental, does, conce...</td>\n",
       "      <td>[I am concerned that “Working Together” does n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>17_following_identified_evidence_care</td>\n",
       "      <td>[following, identified, evidence, care, inques...</td>\n",
       "      <td>[I was informed at the inquest that one local ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>51</td>\n",
       "      <td>18____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[8., 9., 8.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>19_action_taken_response_</td>\n",
       "      <td>[action, taken, response, , , , , , , ]</td>\n",
       "      <td>[Your response must contain details of action ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>20_action_family_following_response</td>\n",
       "      <td>[action, family, following, response, report, ...</td>\n",
       "      <td>[Otherwise you must explain why no action is p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>21_person_report__</td>\n",
       "      <td>[person, report, , , , , , , , ]</td>\n",
       "      <td>[They may send a copy of this report to any pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>22_place_plan_following_does</td>\n",
       "      <td>[place, plan, following, does, care, review, a...</td>\n",
       "      <td>[The Policy describes a “Multi-Disciplinary Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "      <td>23_inquest_assessment_time_issues</td>\n",
       "      <td>[inquest, assessment, time, issues, national, ...</td>\n",
       "      <td>[This meant the assessment was carried out jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>24_response_time__</td>\n",
       "      <td>[response, time, , , , , , , , ]</td>\n",
       "      <td>[You may make representations to me at the tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>25_action_taken_concerned_risk</td>\n",
       "      <td>[action, taken, concerned, risk, ongoing, case...</td>\n",
       "      <td>[In my opinion there is a risk that future dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>26_following_report_family_patients</td>\n",
       "      <td>[following, report, family, patients, response...</td>\n",
       "      <td>[I have sent a copy of my report to the chief ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>44</td>\n",
       "      <td>27_evidence_inquest_heard_relation</td>\n",
       "      <td>[evidence, inquest, heard, relation, clear, re...</td>\n",
       "      <td>[Evidence was heard during the inquest that RA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>28_team___</td>\n",
       "      <td>[team, , , , , , , , , ]</td>\n",
       "      <td>[The ., 1. a., team.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>29____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[vi., •, Date:]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>30_family_service_heard_inquest</td>\n",
       "      <td>[family, service, heard, inquest, , , , , , ]</td>\n",
       "      <td>[They, Senior Coroner for Norfolk, Norfolk Cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>31_period___</td>\n",
       "      <td>[period, , , , , , , , , ]</td>\n",
       "      <td>[I may extend the period., I may extend the pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>32_report_period__</td>\n",
       "      <td>[report, period, , , , , , , , ]</td>\n",
       "      <td>[You are under a duty to respond to this repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>33_action_taken_required_</td>\n",
       "      <td>[action, taken, required, , , , , , , ]</td>\n",
       "      <td>[ACTION SHOULD BE TAKEN and., ACTION SHOULD BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>34_identified_death_risk_plan</td>\n",
       "      <td>[identified, death, risk, plan, number, heard,...</td>\n",
       "      <td>[The post-incident site report further identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>35_risk_available_number_including</td>\n",
       "      <td>[risk, available, number, including, assessmen...</td>\n",
       "      <td>[They were on 1:1 observation due to their hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[5., 5., 5.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>37____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[vii., xv., iv.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>38____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[The Chief Coroner may publish either or both ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>39____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[6., 6., 6.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>40_review_aware_case_guidance</td>\n",
       "      <td>[review, aware, case, guidance, ongoing, lack,...</td>\n",
       "      <td>[Consideration should be given to formally con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>41_did_staff_appropriate_clear</td>\n",
       "      <td>[did, staff, appropriate, clear, time, given, ...</td>\n",
       "      <td>[That relevant training and guidance to equip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>42_number_ongoing_service_mental health</td>\n",
       "      <td>[number, ongoing, service, mental health, ment...</td>\n",
       "      <td>[I heard that if the criteria for referral had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>43_mental_mental health_health_death</td>\n",
       "      <td>[mental, mental health, health, death, family,...</td>\n",
       "      <td>[Obviously, the causes of the decline in their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>44_number_evidence_including_time</td>\n",
       "      <td>[number, evidence, including, time, service, p...</td>\n",
       "      <td>[The fact that the PIN number was common knowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>45____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[ii., ii., ii.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>46_available_identified_concerns_ongoing</td>\n",
       "      <td>[available, identified, concerns, ongoing, con...</td>\n",
       "      <td>[There were no beds available and as a result ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>47_concerned_guidance_ongoing_policy</td>\n",
       "      <td>[concerned, guidance, ongoing, policy, provide...</td>\n",
       "      <td>[This is not in written policy or guidance – w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>48_time_death_number_period</td>\n",
       "      <td>[time, death, number, period, following, did, ...</td>\n",
       "      <td>[They were not checked on from the time they w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>49</td>\n",
       "      <td>24</td>\n",
       "      <td>49_policy_person_aware_risk</td>\n",
       "      <td>[policy, person, aware, risk, does, national, ...</td>\n",
       "      <td>[I am not reassured that BSMHFT staff are hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>50_following_report_family_service</td>\n",
       "      <td>[following, report, family, service, response,...</td>\n",
       "      <td>[I have sent a copy of my report to them and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>51_number_case_time_aware</td>\n",
       "      <td>[number, case, time, aware, including, issues,...</td>\n",
       "      <td>[During the inquest it became apparent that a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>52____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[b., b., b.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>53_response_required_family_</td>\n",
       "      <td>[response, required, family, , , , , , , ]</td>\n",
       "      <td>[I am also under a duty to send them a copy of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>54____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[7., 7 4., 7.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "      <td>55_care_lack_place_appropriate</td>\n",
       "      <td>[care, lack, place, appropriate, service, prov...</td>\n",
       "      <td>[This Care Co-Ordinator will be responsible fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>56</td>\n",
       "      <td>21</td>\n",
       "      <td>56_heard evidence_policy_heard_death</td>\n",
       "      <td>[heard evidence, policy, heard, death, inquest...</td>\n",
       "      <td>[Further, the Court heard evidence to confirm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                        Name  \\\n",
       "0      -1   2022                     -1_did_team_death_staff   \n",
       "1       0    195          0_mental health_mental_health_team   \n",
       "2       1    175            1_staff_guidance_issues_national   \n",
       "3       2    164          2_risk_information_assessment_plan   \n",
       "4       3    136            3_patients_review_heard_evidence   \n",
       "5       4    130            4_concerns_plan_information_care   \n",
       "6       5    123                                 5_family___   \n",
       "7       6    100                                       6____   \n",
       "8       7     81                7_review_provided_care_staff   \n",
       "9       8     80            8_including_risk_assessment_does   \n",
       "10      9     79              9_following_did_staff_response   \n",
       "11     10     73                                      10____   \n",
       "12     11     64  11_staff_provided_heard evidence_available   \n",
       "13     12     62   12_mental_mental health_health_assessment   \n",
       "14     13     59                           13_information___   \n",
       "15     14     59           14_inquest_evidence_concern_heard   \n",
       "16     15     55             15_given_policy_issues_relation   \n",
       "17     16     54      16_including_mental health_mental_does   \n",
       "18     17     52       17_following_identified_evidence_care   \n",
       "19     18     51                                      18____   \n",
       "20     19     50                   19_action_taken_response_   \n",
       "21     20     49         20_action_family_following_response   \n",
       "22     21     48                          21_person_report__   \n",
       "23     22     48                22_place_plan_following_does   \n",
       "24     23     48           23_inquest_assessment_time_issues   \n",
       "25     24     48                          24_response_time__   \n",
       "26     25     47              25_action_taken_concerned_risk   \n",
       "27     26     45         26_following_report_family_patients   \n",
       "28     27     44          27_evidence_inquest_heard_relation   \n",
       "29     28     43                                  28_team___   \n",
       "30     29     42                                      29____   \n",
       "31     30     42             30_family_service_heard_inquest   \n",
       "32     31     41                                31_period___   \n",
       "33     32     41                          32_report_period__   \n",
       "34     33     39                   33_action_taken_required_   \n",
       "35     34     38               34_identified_death_risk_plan   \n",
       "36     35     37          35_risk_available_number_including   \n",
       "37     36     36                                      36____   \n",
       "38     37     35                                      37____   \n",
       "39     38     32                                      38____   \n",
       "40     39     32                                      39____   \n",
       "41     40     31               40_review_aware_case_guidance   \n",
       "42     41     31              41_did_staff_appropriate_clear   \n",
       "43     42     31     42_number_ongoing_service_mental health   \n",
       "44     43     31        43_mental_mental health_health_death   \n",
       "45     44     29           44_number_evidence_including_time   \n",
       "46     45     29                                      45____   \n",
       "47     46     28    46_available_identified_concerns_ongoing   \n",
       "48     47     26        47_concerned_guidance_ongoing_policy   \n",
       "49     48     25                 48_time_death_number_period   \n",
       "50     49     24                 49_policy_person_aware_risk   \n",
       "51     50     24          50_following_report_family_service   \n",
       "52     51     23                   51_number_case_time_aware   \n",
       "53     52     23                                      52____   \n",
       "54     53     23                53_response_required_family_   \n",
       "55     54     22                                      54____   \n",
       "56     55     22              55_care_lack_place_appropriate   \n",
       "57     56     21        56_heard evidence_policy_heard_death   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [did, team, death, staff, evidence, inquest, c...   \n",
       "1   [mental health, mental, health, team, patients...   \n",
       "2   [staff, guidance, issues, national, informatio...   \n",
       "3   [risk, information, assessment, plan, care, pa...   \n",
       "4   [patients, review, heard, evidence, heard evid...   \n",
       "5   [concerns, plan, information, care, place, did...   \n",
       "6                          [family, , , , , , , , , ]   \n",
       "7                                [, , , , , , , , , ]   \n",
       "8   [review, provided, care, staff, report, policy...   \n",
       "9   [including, risk, assessment, does, guidance, ...   \n",
       "10  [following, did, staff, response, service, tim...   \n",
       "11                               [, , , , , , , , , ]   \n",
       "12  [staff, provided, heard evidence, available, c...   \n",
       "13  [mental, mental health, health, assessment, di...   \n",
       "14                    [information, , , , , , , , , ]   \n",
       "15  [inquest, evidence, concern, heard, heard evid...   \n",
       "16  [given, policy, issues, relation, concerns, co...   \n",
       "17  [including, mental health, mental, does, conce...   \n",
       "18  [following, identified, evidence, care, inques...   \n",
       "19                               [, , , , , , , , , ]   \n",
       "20            [action, taken, response, , , , , , , ]   \n",
       "21  [action, family, following, response, report, ...   \n",
       "22                   [person, report, , , , , , , , ]   \n",
       "23  [place, plan, following, does, care, review, a...   \n",
       "24  [inquest, assessment, time, issues, national, ...   \n",
       "25                   [response, time, , , , , , , , ]   \n",
       "26  [action, taken, concerned, risk, ongoing, case...   \n",
       "27  [following, report, family, patients, response...   \n",
       "28  [evidence, inquest, heard, relation, clear, re...   \n",
       "29                           [team, , , , , , , , , ]   \n",
       "30                               [, , , , , , , , , ]   \n",
       "31      [family, service, heard, inquest, , , , , , ]   \n",
       "32                         [period, , , , , , , , , ]   \n",
       "33                   [report, period, , , , , , , , ]   \n",
       "34            [action, taken, required, , , , , , , ]   \n",
       "35  [identified, death, risk, plan, number, heard,...   \n",
       "36  [risk, available, number, including, assessmen...   \n",
       "37                               [, , , , , , , , , ]   \n",
       "38                               [, , , , , , , , , ]   \n",
       "39                               [, , , , , , , , , ]   \n",
       "40                               [, , , , , , , , , ]   \n",
       "41  [review, aware, case, guidance, ongoing, lack,...   \n",
       "42  [did, staff, appropriate, clear, time, given, ...   \n",
       "43  [number, ongoing, service, mental health, ment...   \n",
       "44  [mental, mental health, health, death, family,...   \n",
       "45  [number, evidence, including, time, service, p...   \n",
       "46                               [, , , , , , , , , ]   \n",
       "47  [available, identified, concerns, ongoing, con...   \n",
       "48  [concerned, guidance, ongoing, policy, provide...   \n",
       "49  [time, death, number, period, following, did, ...   \n",
       "50  [policy, person, aware, risk, does, national, ...   \n",
       "51  [following, report, family, service, response,...   \n",
       "52  [number, case, time, aware, including, issues,...   \n",
       "53                               [, , , , , , , , , ]   \n",
       "54         [response, required, family, , , , , , , ]   \n",
       "55                               [, , , , , , , , , ]   \n",
       "56  [care, lack, place, appropriate, service, prov...   \n",
       "57  [heard evidence, policy, heard, death, inquest...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [The evidence heard at the Inquest was that th...  \n",
       "1   [At HMP Haverigg there was inadequate mental h...  \n",
       "2   [There is a lack of national guidance for both...  \n",
       "3   [This gap in information can have an impact on...  \n",
       "4   [I also heard evidence to suggest that prescri...  \n",
       "5   [They did not receive a care plan that was ade...  \n",
       "6            [2., They's family 3., They's family 3.]  \n",
       "7                                        [1., 1., 1.]  \n",
       "8   [My concerns relating to the inadequacy of the...  \n",
       "9   [There is the potential for the risk of harm t...  \n",
       "10  [In the case of the individual, as can be seen...  \n",
       "11                                       [3., 3., 3.]  \n",
       "12  [I heard evidence that training on dealing wit...  \n",
       "13  [She felt she was not being listened to by com...  \n",
       "14                       [4., 4., For information 4.]  \n",
       "15  [During the Inquest evidence was heard that: ­...  \n",
       "16  [Consideration should be given to whether any ...  \n",
       "17  [I am concerned that “Working Together” does n...  \n",
       "18  [I was informed at the inquest that one local ...  \n",
       "19                                       [8., 9., 8.]  \n",
       "20  [Your response must contain details of action ...  \n",
       "21  [Otherwise you must explain why no action is p...  \n",
       "22  [They may send a copy of this report to any pe...  \n",
       "23  [The Policy describes a “Multi-Disciplinary Re...  \n",
       "24  [This meant the assessment was carried out jus...  \n",
       "25  [You may make representations to me at the tim...  \n",
       "26  [In my opinion there is a risk that future dea...  \n",
       "27  [I have sent a copy of my report to the chief ...  \n",
       "28  [Evidence was heard during the inquest that RA...  \n",
       "29                              [The ., 1. a., team.]  \n",
       "30                                    [vi., •, Date:]  \n",
       "31  [They, Senior Coroner for Norfolk, Norfolk Cor...  \n",
       "32  [I may extend the period., I may extend the pe...  \n",
       "33  [You are under a duty to respond to this repor...  \n",
       "34  [ACTION SHOULD BE TAKEN and., ACTION SHOULD BE...  \n",
       "35  [The post-incident site report further identif...  \n",
       "36  [They were on 1:1 observation due to their hig...  \n",
       "37                                       [5., 5., 5.]  \n",
       "38                                   [vii., xv., iv.]  \n",
       "39  [The Chief Coroner may publish either or both ...  \n",
       "40                                       [6., 6., 6.]  \n",
       "41  [Consideration should be given to formally con...  \n",
       "42  [That relevant training and guidance to equip ...  \n",
       "43  [I heard that if the criteria for referral had...  \n",
       "44  [Obviously, the causes of the decline in their...  \n",
       "45  [The fact that the PIN number was common knowl...  \n",
       "46                                    [ii., ii., ii.]  \n",
       "47  [There were no beds available and as a result ...  \n",
       "48  [This is not in written policy or guidance – w...  \n",
       "49  [They were not checked on from the time they w...  \n",
       "50  [I am not reassured that BSMHFT staff are hand...  \n",
       "51  [I have sent a copy of my report to them and t...  \n",
       "52  [During the inquest it became apparent that a ...  \n",
       "53                                       [b., b., b.]  \n",
       "54  [I am also under a duty to send them a copy of...  \n",
       "55                                     [7., 7 4., 7.]  \n",
       "56  [This Care Co-Ordinator will be responsible fo...  \n",
       "57  [Further, the Court heard evidence to confirm ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic(#embedding_model=embedding_model, # ...custom embeddings\n",
    "                       umap_model=umap_model, # ...dimensionality reduction\n",
    "                       hdbscan_model=hdbscan_model, # ...clustering\n",
    "                       vectorizer_model=vectorizer_model, # ...vectoriser\n",
    "                       )\n",
    "\n",
    "# Fit the model to data\n",
    "topics, probabilities = topic_model.fit_transform(processed_sentences)\n",
    "\n",
    "# Find unique topics\n",
    "unique_topics = set(topics)\n",
    "num_unique_topics = len(unique_topics)\n",
    "\n",
    "print(f\"Number of unique topics identified: {num_unique_topics}\")\n",
    "print(\"\")\n",
    "\n",
    "# Get topic information\n",
    "topic_model.get_topic_info()\n",
    "#print(\"Topic Info:\\n\", topic_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PFD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
